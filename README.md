# Visionary
This project processes real-time video feeds from phones or cameras and utilizes advanced AI models (LLAMA3, LLAVA) to provide verbal feedback about the surroundings. It offers visually impaired users an intuitive and responsive way to understand their environment. Built with Python, OpenCV, and Tkinter for accessibility and ease of use.
