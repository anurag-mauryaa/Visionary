# Visionary

**Empowering the Visually Impaired with Real-Time Visual Assistance using AI.**
This project processes real-time video feeds from phones or cameras and utilizes advanced AI models (LLAMA3, LLAVA) to provide verbal feedback about the surroundings. It offers visually impaired users an intuitive and responsive way to understand their environment. Built with Python, OpenCV, and (formely with Tkinter) ,React for accessibility and ease of use.
Key Features:

    Real-time video feed processing.
    AI-based image captioning and environment recognition.
    User-friendly interface designed with accessibility in mind.

Technologies:

    Python
    Ollama (LLAMA3, LLAVA)
    OpenCV
    Gradio

## I have deleted the old project as it was made with tkinter for college project but had a lot of bad practices and bad UX experience.
## I am re-implementing, and now migrating to React for better UX
